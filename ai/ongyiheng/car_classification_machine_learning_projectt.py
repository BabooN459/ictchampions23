# -*- coding: utf-8 -*-
"""Car Classification Machine Learning Projectt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AUC8mkn-GekiDJlIA90iY-xZcAt7F5aA
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

column_features = ['Len(m)', 'Wb(m)', 'Door', 'W(100kg)', 'Seats','E_S(1000cc)','S_F','Price']
df = pd.read_csv('cars_data.csv', names=column_features)
df.head()

no_of_exp_cars = len(df[df["Price"]=="Expensive"]) #df["Price"] finds the column feature in the database
#df[df["Price"]=='Expensive'] finds the column features with that value.
#The value given will be an int and needs to be converted into str
print('The number of expensive cars is '+ str(no_of_exp_cars))
no_of_mod_cars = len(df[df["Price"]=="Moderate"])
print('The number of moderate cars is '+ str(no_of_mod_cars))
no_of_chp_cars = len(df[df["Price"]=="Cheap"])
print('The number of cheap cars is '+ str(no_of_chp_cars))

sns.pairplot(df, hue='Price') #visualise dataset with defining feature as price

# Seperate features and target

# Before we bgin Machine Learning, we need to spilt up the table into 2 Arrays
data = df.values    # Take the values from the table and create a new table called 'data'
X = data[:,0:7]     # Take on the first 7 columns (Features) and store it in X
Y = data[:,7]       # Take on the Class columns and store it in Y

# Calculate avarage of each features for all classes

# Using the X and Y arrays created in the previous cell, we are going to plot the averages of each column.
# In this cell, we use some array calculations to help us find the averages.
Y_Data = np.array([np.average(X[:, i][Y==j].astype('float32')) for i in range (X.shape[1]) for j in (np.unique(Y))])
Y_Data_reshaped = Y_Data.reshape(7,3)
Y_Data_reshaped = np.swapaxes(Y_Data_reshaped, 0, 1)
X_axis = np.arange(len(column_features)-1)
width = 0.25

# Plot the avarage
# Using the MatPlotLib library (as plt) we can plt the averages of each type of Price of car based on its features.
plt.bar(X_axis, Y_Data_reshaped[0], width, label = 'Cheap')
plt.bar(X_axis+width, Y_Data_reshaped[1], width, label = 'Moderate')
plt.bar(X_axis+width*2, Y_Data_reshaped[2], width, label = 'Expensive')
plt.xticks(X_axis, column_features[:7])
plt.xlabel("Features")
plt.ylabel("Values")
plt.legend(bbox_to_anchor=(1.3,1))
plt.show()

# Study the table below. in the x-axis, we have the Features, in the Y-axis we have the Value.
# Each bar represents the average of that Feature for each Price of the car.
# For example, only looking at Len(m), i can see that the average Len(m) of each type of car is
#   between 4-5 meters.

# Split the data to train and test dataset.
# Before we can apply Machine Learning, we need to split our dataset into Training and Testing data
# Training data is the data used to train our Machine
# Testing data will be later used to validate whether our Machine is well trained or not.

# We will use the sklearn library to split our data into Training and Testing.
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.05)   #split based on 70:30 ratio.

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)

# Fit the K-NN classifier to the training data
knn.fit(X_train, y_train)

# Make predictions with K-NN
y_pred_knn = knn.predict(X_test)

# Calculate the accuracy
# Think of accuracy as shooting arrows at a target. We dont want the arrows
# to be far from the bullseye!

# So the higher the Accuracy is to 1 (1 means 100% accurate), the better our test went.

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred_knn)

# Support vector machine algorithm
from sklearn.svm import SVC
# using the SKLearn library to call the Support Vector Machine algorithms
svn = SVC()
svn.fit(X_train, y_train)

predictions = svn.predict(X_test)
from sklearn.metrics import accuracy_score
accuracy_score(y_test, predictions)

from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

# Make predictions with K-NN
predictions = knn.predict(X_test)

# Make predictions with SVM
predictions = svn.predict(X_test) # Now that our Training is complete, it is time to test our data.

# Calculate the accuracy
# Think of accuracy as shooting arrows at a target. We dont want the arrows
# to be far from the bullseye!

# So the higher the Accuracy is to 1 (1 means 100% accurate), the better our test went.

from sklearn.metrics import accuracy_score
accuracy_score(y_test, predictions)

# A detailed classification report

# Time to tabulate the results from our tests and predictions
# We only need to look at Precision and Recall

# What is the Precision and Recall of the 3 prices?
# Which price has the lowest Precision and Recall? What does that mean?

from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

# Lets create an Array of data of 3 types of Prices/cars.
# For each dimension of the Array, i only have 7 columns, each col represents
# the features of the car.

#Run the cell and lets see how well our Machine predicts the Prices of these cars.

X_new = np.array([[4.331,1.958,2,9,2,4.1,1],[3.617,1.484,4,11.52,4,2.9,0],[3.546,1.675,4,15.79,8,1.6,0]])


#Prediction of the species from the input vector
prediction = knn.predict(X_new)
print("Prediction of price: {}".format(prediction))